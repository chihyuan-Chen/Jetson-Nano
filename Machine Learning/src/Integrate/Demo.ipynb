{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73c04009-f3c5-4090-a271-0f2ac574a760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108a070e351f4a3eb3b680311b6a6695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00Câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "car_blocked_slider = widgets.FloatSlider(description='car_blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "caution_blocked_slider = widgets.FloatSlider(description='caution_blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "limit_blocked_slider = widgets.FloatSlider(description='limit_blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "pedestrian_blocked_slider = widgets.FloatSlider(description='pedestrian_blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "scooter_blocked_slider = widgets.FloatSlider(description='scooter_blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.HBox([image, car_blocked_slider, caution_blocked_slider, limit_blocked_slider, pedestrian_blocked_slider, scooter_blocked_slider]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f4259e-cfae-44cf-83c0-53a52d4cd95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebed3f36-b578-499d-987a-cdbcc517a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "road = torchvision.models.resnet18(pretrained=False)\n",
    "road.fc = torch.nn.Linear(512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e2f7a82-0c23-41c6-bd85-6c2aa7b026dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road.load_state_dict(torch.load('5000_steering_model_xy.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00568ac5-5bec-4c0a-9b04-7eeae5e891f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "car = torchvision.models.alexnet(pretrained=False)\n",
    "car.classifier[6] = torch.nn.Linear(car.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34257bc2-d6ca-419f-820e-48c315f56c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.load_state_dict(torch.load('car_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e078c11-6d9c-497c-8344-c02925142b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "caution = torchvision.models.alexnet(pretrained=False)\n",
    "caution.classifier[6] = torch.nn.Linear(caution.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f61dfa-bbc8-4f87-a125-d2b5fe7d9f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caution.load_state_dict(torch.load('caution_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a1e0f63-9afa-4984-8f1d-60c1525fa1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = torchvision.models.alexnet(pretrained=False)\n",
    "limit.classifier[6] = torch.nn.Linear(limit.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6af0fe5d-a449-4777-b9dd-cf5b9a645dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit.load_state_dict(torch.load('limit_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c225074-f4a8-4b41-b8bc-10bebaaab80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrian = torchvision.models.alexnet(pretrained=False)\n",
    "pedestrian.classifier[6] = torch.nn.Linear(pedestrian.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f16f1665-da4c-4324-82bf-fe002da9a44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pedestrian.load_state_dict(torch.load('pedestrian_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e87d7ba-9dff-47ac-9822-2f611ec783e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scooter = torchvision.models.alexnet(pretrained=False)\n",
    "scooter.classifier[6] = torch.nn.Linear(scooter.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fec32b13-0d11-410d-a818-b12a3d83b7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scooter.load_state_dict(torch.load('scooter_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73ba7c34-551e-42e1-8868-e78c60b64b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_device = torch.device('cuda')\n",
    "road = road.to(road_device)\n",
    "road = road.eval().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5809d0ab-5e57-4795-81c6-7f07f87291a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_device = torch.device('cuda')\n",
    "car = car.to(car_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e1c80d1-d194-4fe5-b0c9-6bc77f223a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "caution_device = torch.device('cuda')\n",
    "caution = caution.to(caution_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "019eec0a-9d79-4e2a-a4c4-54c0e4022843",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_device = torch.device('cuda')\n",
    "limit = limit.to(limit_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba251d04-abe4-40a7-8013-86dd1de9bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrian_device = torch.device('cuda')\n",
    "pedestrian = pedestrian.to(pedestrian_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23097262-c609-496c-821d-167f5a05ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "scooter_device = torch.device('cuda')\n",
    "scooter = scooter.to(scooter_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b873388-e991-4e8b-bac1-408d229c20ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "mean1 = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev1 = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean1, stdev1)\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(road_device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "def preprocess1(camera_value):\n",
    "    global car_device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(car_device)\n",
    "    x = x[None, ...]\n",
    "    return x\n",
    "\n",
    "def preprocess2(camera_value):\n",
    "    global caution_device\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(caution_device)\n",
    "    x = x[None, ...]\n",
    "    return x\n",
    "\n",
    "def preprocess3(camera_value):\n",
    "    global limit_device\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(limit_device)\n",
    "    x = x[None, ...]\n",
    "    return x\n",
    "\n",
    "def preprocess4(camera_value):\n",
    "    global pedestrian_device\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(pedestrian_device)\n",
    "    x = x[None, ...]\n",
    "    return x\n",
    "\n",
    "def preprocess5(camera_value):\n",
    "    global scooter_device\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(scooter_device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebb5e78e-af2f-4949-9a12-b88190de11a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39ee1a93a3541c5942f653f1740d40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='speed gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a0997ca7a3440fadca2acff67dd732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.2, description='steering gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7391afd116d546ee9dfbea646d8ce6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering kd', max=0.5, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbfae963520457cbc6630c41186af8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering bias', max=0.3, min=-0.3, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.2, description='steering gain')\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0874c6b-7a61-49f7-a3f4-31270b7e17fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35382aac0b74740ade2c6301cfb2788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, description='y', max=1.0, orientation='vertical'), FloatSlider(value=0.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c2afa74e2b4e96ab70b14db830f991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96a60ca0e7c46a380fc38f8d1c0c5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "display(ipywidgets.HBox([y_slider, speed_slider]))\n",
    "display(x_slider, steering_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b2f6c-9a05-4527-9a6e-d8e900828aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last, car_blocked_slider, caution_blocked_slider, limit_blocked_slider, pedestrian_blocked_slider, scooter_blocked_slider, robot\n",
    "    image = change['new']\n",
    "\n",
    "    x0 = preprocess1(image)\n",
    "    y0 = car(x0)\n",
    "    x1 = preprocess2(image)\n",
    "    y1 = caution(x1)\n",
    "    x2 = preprocess3(image)\n",
    "    y2 = limit(x2)\n",
    "    x3 = preprocess4(image)\n",
    "    y3 = pedestrian(x3)\n",
    "    x4 = preprocess5(image)\n",
    "    y4 = scooter(x4)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y0 = F.softmax(y0, dim=1)\n",
    "    y1 = F.softmax(y1, dim=1)\n",
    "    y2 = F.softmax(y2, dim=1)\n",
    "    y3 = F.softmax(y3, dim=1)\n",
    "    y4 = F.softmax(y4, dim=1)\n",
    "    \n",
    "    car_blocked = float(y0.flatten()[0])\n",
    "    caution_blocked = float(y1.flatten()[0])\n",
    "    limit_blocked = float(y2.flatten()[0])\n",
    "    pedestrian_blocked = float(y3.flatten()[0])\n",
    "    scooter_blocked = float(y4.flatten()[0])\n",
    "    \n",
    "    car_blocked_slider.value = car_blocked\n",
    "    caution_blocked_slider.value = caution_blocked\n",
    "    limit_blocked_slider.value = limit_blocked\n",
    "    pedestrian_blocked_slider.value = pedestrian_blocked\n",
    "    scooter_blocked_slider.value = scooter_blocked\n",
    "    \n",
    "    xy = road(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "    \n",
    "    x_slider.value = x\n",
    "    y_slider.value = y\n",
    "    \n",
    "    speed_slider.value = speed_gain_slider.value\n",
    "    \n",
    "    angle = np.arctan2(x, y)\n",
    "    pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "    angle_last = angle\n",
    "    \n",
    "    steering_slider.value = pid + steering_bias_slider.value\n",
    "    \n",
    "    if car_blocked > 0.9 or caution_blocked > 0.9 or limit_blocked > 0.9 or pedestrian_blocked > 0.9 or scooter_blocked > 0.9:\n",
    "        robot.stop()\n",
    "        \n",
    "    else:\n",
    "        robot.left_motor.value = max(min(speed_slider.value + steering_slider.value, 1.0), 0.0)\n",
    "        robot.right_motor.value = max(min(speed_slider.value - steering_slider.value, 1.0), 0.0)\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "    \n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f9be1-0573-4fb9-b6b9-14652ea98ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebb953e-e84f-4036-bb04-2945646bb0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab256c97-c53b-47ac-bcfc-b8fd6cf988c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink()  # don't stream to browser (will still run camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42230806-f782-4df7-a290-f57b50d6bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
